# Interaktives Tic-Tac-Toe Spiel

## ğŸ® Spielmodi

Das Programm bietet 5 verschiedene Spielmodi:

### 1ï¸âƒ£ Q-Learning vs Zufallsspieler
- Q-Learning Algorithmus spielt gegen Zufallsspieler
- WÃ¤hlbare Anzahl an Spielen (z.B. 1000)
- Zeigt Statistiken: Siege, Niederlagen, Unentschieden

### 2ï¸âƒ£ Neural Network vs Zufallsspieler
- Deep Q-Network spielt gegen Zufallsspieler
- Trainiert NN zuerst (10.000 Episoden)
- Zeigt Statistiken nach allen Spielen

### 3ï¸âƒ£ Q-Learning vs Menschlicher Spieler â­
- **Spiele selbst gegen Q-Learning!**
- WÃ¤hle deine Farbe (X oder O)
- Interaktive Eingabe Ã¼ber Terminal
- Visuelles Spielfeld

### 4ï¸âƒ£ Neural Network vs Menschlicher Spieler â­
- **Spiele selbst gegen Neural Network!**
- Trainiert NN zuerst
- WÃ¤hle deine Farbe (X oder O)
- Interaktive Eingabe

### 5ï¸âƒ£ Q-Learning vs Neural Network
- Direkter Vergleich der beiden Algorithmen
- WÃ¤hlbare Anzahl an Spielen
- Zeigt welcher Algorithmus besser ist

---

## ğŸš€ Starten

```bash
# Kompilieren
javac -cp "lib/tic_tac_toe.jar" -d target/classes src/main/java/tic_tac_toe_mi/*.java src/main/java/tic_tac_toe_mi/nn/*.java

# Starten
java -cp "target/classes:lib/tic_tac_toe.jar" tic_tac_toe_mi.InteraktivesSpiel
```

---

## ğŸ“‹ Bedienung

### HauptmenÃ¼
```
ğŸ“‹ HAUPTMENÃœ - WÃ¤hle einen Spielmodus:

  1ï¸âƒ£  Q-Learning vs Zufallsspieler
  2ï¸âƒ£  Neural Network vs Zufallsspieler
  3ï¸âƒ£  Q-Learning vs Menschlicher Spieler (Du!)
  4ï¸âƒ£  Neural Network vs Menschlicher Spieler (Du!)
  5ï¸âƒ£  Q-Learning vs Neural Network (Direktvergleich)
  0ï¸âƒ£  Beenden

>
```

### Spielfeld-Eingabe (wenn du spielst)
```
  Aktuelles Spielfeld:
  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
  â”‚   â”‚   â”‚   â”‚
  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚   â”‚ X â”‚   â”‚
  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚   â”‚   â”‚   â”‚
  â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

Gib Zeile (0-2) und Spalte (0-2) ein, z.B. '1 1' fÃ¼r Mitte:
>
```

**Koordinaten-System:**
```
     Spalte
     0 1 2
   â”Œâ”€â”€â”€â”€â”€â”€â”€
 0 â”‚ 0,0  0,1  0,2
Z 1 â”‚ 1,0  1,1  1,2
e 2 â”‚ 2,0  2,1  2,2
i
l
e
```

**Beispiel-Eingaben:**
- `0 0` - Oben links
- `1 1` - Mitte
- `2 2` - Unten rechts
- `exit` - Spiel beenden

---

## ğŸ“Š Beispiel-Output

### Q-Learning vs Zufallsspieler (1000 Spiele)
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Q-Learning vs Zufallsspieler                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Spiele 1,000 Partien...

Spiel  100 | Siege:   73 | Siegrate: 73.0%
Spiel  200 | Siege:  147 | Siegrate: 73.5%
...
Spiel 1000 | Siege:  736 | Siegrate: 73.6%

ğŸ“Š ENDERGEBNIS:
Siege:         736 (73.6%)
Niederlagen:   214 (21.4%)
Unentschieden:  50 (5.0%)
```

### Q-Learning vs Du (Interaktiv)
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Q-Learning vs Menschlicher Spieler              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Dein Name: Johannes

WÃ¤hle deine Farbe:
1) X (du fÃ¤ngst an)
2) O (Q-Learning fÃ¤ngt an)
> 1

Spiel startet! (Gib 'exit' ein um abzubrechen)

  Aktuelles Spielfeld:
  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
  â”‚   â”‚   â”‚   â”‚
  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚   â”‚   â”‚   â”‚
  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚   â”‚   â”‚   â”‚
  â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

Johannes (Kreuz), wÃ¤hle dein Feld:
Gib Zeile (0-2) und Spalte (0-2) ein, z.B. '1 1' fÃ¼r Mitte:
> 1 1

Q-Learning denkt nach...
Q-Learning wÃ¤hlt: Zeile 0, Spalte 0

  Aktuelles Spielfeld:
  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
  â”‚ O â”‚   â”‚   â”‚
  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚   â”‚ X â”‚   â”‚
  â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚   â”‚   â”‚   â”‚
  â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

...
```

### Q-Learning vs Neural Network (500 Spiele)
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Q-Learning vs Neural Network                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Trainiere Neural Network (10.000 Episoden)...
Episode 10,000 | Îµ=0.0100 | Buffer=10,000

âœ… Training abgeschlossen in 14.52 Sekunden
   Geschwindigkeit: 689 Episoden/Sekunde

Spiele 500 Partien...

Spiel  100 | Q:   52 (52.0%) | NN:   45 (45.0%)
Spiel  200 | Q:  105 (52.5%) | NN:   91 (45.5%)
...
Spiel  500 | Q:  262 (52.4%) | NN:  226 (45.2%)

ğŸ“Š ENDERGEBNIS:
Q-Learning:    262 Siege (52.4%)
Neural Net:    226 Siege (45.2%)
Unentschieden:  12 (2.4%)

ğŸ† Q-Learning gewinnt den Vergleich!
```

---

## ğŸ¯ Tipps zum Spielen

### Gegen Q-Learning
- Q-Learning ist sehr stark trainiert (73.6% Win-Rate)
- Versuche die Mitte zu kontrollieren
- Blockiere Q-Learning's Gewinnchancen frÃ¼h
- Erstelle "Gabeln" (zwei GewinnmÃ¶glichkeiten gleichzeitig)

### Gegen Neural Network
- NN ist auch stark (78.7% Win-Rate)
- Nutze gleiche Strategien wie gegen Q-Learning
- NN kann manchmal Ã¼berraschende ZÃ¼ge machen

### Allgemeine Tic-Tac-Toe Strategie
1. **Mitte nehmen** - Gibt die meisten Gewinnoptionen
2. **Ecken bevorzugen** - Mehr Gewinnlinien als Kanten
3. **Gabel erstellen** - Zwei GewinnmÃ¶glichkeiten gleichzeitig
4. **Gegner blocken** - Verhindere Drei-in-einer-Reihe

---

## ğŸ”§ Technische Details

### Architektur

**Q-Learning:**
- Tabular Q-Learning (HashMap)
- 5,636 entdeckte States (93.2% Coverage)
- Î±=0.30, Î³=0.99, Îµ=0.40
- Training: 100k Spiele in 0.18s

**Neural Network:**
- Deep Q-Network (DQN)
- Architektur: 9 â†’ 128 â†’ 64 â†’ 9
- 10,121 Parameter
- Training: 10k Episoden in ~15s

### Performance

| Metrik | Q-Learning | Neural Network |
|--------|------------|----------------|
| Win-Rate vs Random | 73.6% | 78.7% |
| Training-Zeit | 0.18s | 14.6s |
| Code-KomplexitÃ¤t | ~500 LOC | ~1,140 LOC |
| Interpretierbar | âœ… Ja | âŒ Nein |

---

## ğŸ› Troubleshooting

### "IllegalerZugException"
- Stelle sicher dass du Koordinaten zwischen 0-2 eingibst
- PrÃ¼fe dass das Feld noch frei ist

### "NumberFormatException"
- Gib Zahlen ein, keine Buchstaben
- Format: `Zeile Leerzeichen Spalte` (z.B. `1 1`)

### Programm hÃ¤ngt
- DrÃ¼cke `Ctrl+C` zum Abbrechen
- Oder gib `exit` ein

---

## ğŸ“š Lernressourcen

Dieses Projekt demonstriert:
- **Reinforcement Learning** (Q-Learning)
- **Deep Reinforcement Learning** (DQN)
- **Neural Networks** (MLP mit Backpropagation)
- **Vergleich verschiedener RL-AnsÃ¤tze**

Perfekt zum Lernen und Experimentieren mit KI-Algorithmen!

---

**Viel SpaÃŸ beim Spielen! ğŸ®**
